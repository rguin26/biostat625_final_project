---
title: "Survival Analysis and Machine Learning Methodologies for Bone Marrow Cancer"
output:
  pdf_document:
    fig_width: 5.5
    fig_height: 3.5
  html_document:
    toc: yes
    theme: united
author: Yitian Cai, Rudra Guin, Jorge Portugal
date: "12/17/2021"
fontsize: 12pt
---

```{r setup, include=FALSE}
# header-includes: \usepackage{setspace}\doublespacing
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```


# Introduction

For this project, our group chose to perform statistical analysis using the Clinical Data Set from the Clinical Package of bone marrow cancer data. It was collected from the National Cancer Institute (NCI) genomic data portal. The version of the dataset we used was released by October 29, 2021. The bone marrow cancer can damage the bones, immune system, kidneys, and red blood cell count. The dataset contains 16,029 different cases of bone marrow cancer. We planned on using it for survival analysis and machine learning methodologies.

# Data Description

The dataset contains 47 clinical variables. At the beginning, we tried to include the biospecimen data in order to increase the dimension of our dataset, but we found that most of those genomics data were missing, which would not provide us too much help. So, we decided to stick with the clinical data of bone marrow. Vital status means whether the patients were alive or dead at the time the data were collected. Our dataset contains 9,036 alive cases and 3,551 dead cases. Others were either missing or recorded as "unknown" or "not reported".

# Data Preprocessing

The initial dataset had several missing values among the different features. So, before going into analysis and modeling, we had to clean up and pre-process the data. First, we removed all the observations that had missing values for vital status, because vital status was the one that we wish to forecast or predict and we cannot use missing values for prediction. We tried to see if the missing values in vital status were censored. However, none of the other variables that had similar information, such as days to last follow up, days to death, or days to birth, provided any useful information, since they were also missing. So, we decided to drop them all. Then, we decided to remove variables with more than 8,000 missing values. Because it means that more than half of the observations in these variables were missing, which we believed would cause too much inaccuracy after data imputation. After that, we used the mice function to impute those missing values. The mice package implemented a method to deal with missing data and it generated Multivariate Imputations by Chained Equations. And finally, we randomly split the dataset into two where the training set contained 70% of the data, and the test set contained the rest 30% of the data.

```{r, echo=FALSE, message=FALSE}
# Necessary libraries
library(mice)
library(fastDummies)
library(neuralnet)
library(caret)
library(randomForest)
library(caTools)
library(survival)
library(ranger)
library(ggplot2)
library(dplyr)
library(ggfortify)
library(survminer)
library(knitr)
set.seed(625)
```


```{r, echo=FALSE}
# Loading the clinical data
data <- read.delim(file = 'clinical_bone.tsv', sep = '\t', header = TRUE)
data[data == "\'--"] <- "NULL"
is.na(data) <- data == "NULL"
data <- data[, colSums(is.na(data)) < nrow(data)]
#names(data)

# Transforming unknown values into NAs
data[data=="not reported"] <- NA
data[data=="Not Reported"] <- NA
data[data=="unknown"] <- NA
data[data=="Unknown"] <- NA
data[data=="not allowed to collect"] <- NA
#summary(data)
```

```{r, echo=FALSE}
# Tranforming the type of variables into numerical or categorical
data <- subset(data, select = -c(case_id, case_submitter_id))
data <- transform(
  data,
  project_id=as.factor(project_id),
  age_at_index=as.numeric(age_at_index),
  age_is_obfuscated=as.factor(age_is_obfuscated),
  cause_of_death=as.factor(cause_of_death),
  days_to_birth=as.numeric(days_to_birth),
  days_to_death=as.numeric(days_to_death),
  ethnicity=as.factor(ethnicity),
  gender=as.factor(gender),
  race=as.factor(race),
  vital_status=as.factor(vital_status),
  year_of_birth=as.numeric(year_of_birth),
  year_of_death=as.numeric(year_of_death),
  age_at_diagnosis=as.numeric(age_at_diagnosis),
  ann_arbor_b_symptoms=as.factor(ann_arbor_b_symptoms),
  ann_arbor_extranodal_involvement=as.factor(ann_arbor_extranodal_involvement),
  ann_arbor_pathologic_stage=as.factor(ann_arbor_pathologic_stage),
  burkitt_lymphoma_clinical_variant=as.factor(burkitt_lymphoma_clinical_variant),
  classification_of_tumor=as.factor(classification_of_tumor),
  days_to_diagnosis=as.numeric(days_to_diagnosis),
  days_to_last_follow_up=as.numeric(days_to_last_follow_up),
  days_to_last_known_disease_status=as.numeric(days_to_last_known_disease_status),
  inss_stage=as.numeric(inss_stage),
  iss_stage=as.factor(iss_stage),
  last_known_disease_status=as.factor(last_known_disease_status),
  method_of_diagnosis=as.factor(method_of_diagnosis),
  morphology=as.factor(morphology),
  #primary_diagnosis=as.factor(primary_diagnosis),
  prior_malignancy=as.factor(prior_malignancy),
  prior_treatment=as.factor(prior_treatment),
  progression_or_recurrence=as.factor(progression_or_recurrence),
  #site_of_resection_or_biopsy=as.factor(site_of_resection_or_biopsy),
  synchronous_malignancy=as.factor(synchronous_malignancy),
  tissue_or_organ_of_origin=as.factor(tissue_or_organ_of_origin),
  tumor_grade=as.factor(tumor_grade),
  year_of_diagnosis=as.numeric(year_of_diagnosis),
  days_to_treatment_end=as.numeric(days_to_treatment_end),
  days_to_treatment_start=as.numeric(days_to_treatment_start),
  initial_disease_status=as.factor(initial_disease_status),
  number_of_cycles = as.factor(number_of_cycles),
  regimen_or_line_of_therapy = as.factor(regimen_or_line_of_therapy),
  therapeutic_agents=as.factor(therapeutic_agents),
  treatment_anatomic_site=as.factor(treatment_anatomic_site),
  treatment_dose=as.factor(treatment_dose),
  treatment_intent_type=as.factor(treatment_intent_type),
  treatment_or_therapy=as.factor(treatment_or_therapy),
  treatment_outcome=as.factor(treatment_outcome),
  treatment_type=as.factor(treatment_type)
)
```



```{r, echo=FALSE}
# Remove variables with missing values in vital status
data2 <- data[!is.na(data$vital_status), ]

# Remove variables with more than 8,000 missing values
rem <- colSums(is.na(data)) > 8000
data2 <- subset(data2, select = -c(age_is_obfuscated, cause_of_death, days_to_death, year_of_birth, year_of_death, ann_arbor_b_symptoms, ann_arbor_extranodal_involvement, ann_arbor_pathologic_stage, burkitt_lymphoma_clinical_variant, classification_of_tumor, days_to_diagnosis, inss_stage, last_known_disease_status, method_of_diagnosis, prior_malignancy, prior_treatment, progression_or_recurrence, synchronous_malignancy, tumor_grade, year_of_diagnosis, days_to_treatment_end, days_to_treatment_start, initial_disease_status, number_of_cycles, regimen_or_line_of_therapy, therapeutic_agents, treatment_anatomic_site, treatment_dose, treatment_intent_type, treatment_or_therapy, treatment_outcome, treatment_type))

# summary(data)
```

```{r, echo=FALSE}
# Impute missing values
data_imp <- mice(data2, m=5, method = "sample", printFlag = FALSE)
```


# Analysis

## Survival Analysis

For the first part of this project, we decided to do some exploratory survival analysis. However, due to the nature of how the data was collected, as well as how vastly incomplete the data was, some assumptions had to have been made. After looking at the dataset dictionary, the definition of the variable Vital Status is defined as “the survival state of the person registered on the protocol”. That is the only clear definition given out for that variable. As a result, we make the assumption that even though a patient’s info is censored, we consider them dead. 

Additionally, our time event variable is “days to last follow-up” . We were recommended to go over the “days to death” variable and perhaps use that as our time event variable, but upon further examination, that variable had a large proportion of missing values and highly skewed the data. 

Our main goal was to obtain results from machine learning methods. While the Survival Analysis portion may not follow the traditional guidelines (due to the vastly incompleteness of the dataset). It is mostly meant to be an exploratory analysis to give us and the readers a feel for the data at hand.  
```{r,echo=FALSE,warning=FALSE}
#mainly just data prep
rem <- colSums(is.na(data)) > 1000

data$vital_status<-if_else(data$vital_status == "Alive",0,1)


data$ethnicity<-droplevels(data$ethnicity)
data$gender<-droplevels(data$gender)

data$trueage<-round(data$age_at_diagnosis/365)
data$agecat<-as.numeric(data$trueage)
data$agecat[data$agecat >100 ]<-NA

data$agecat[data$agecat>20&data$agecat<41]<-"21yo - 40yo"
data$agecat[data$agecat>40&data$agecat<61]<-"41yo - 60yo yo"
data$agecat[data$agecat>=0&data$agecat<21]<-"20yo or younger"
data$agecat[data$agecat==3|data$agecat==4]<-"20yo or younger"
data$agecat[data$agecat>60]<- "60+ yo"
data$agecat<-as.factor(data$agecat)
data$agecat<-droplevels(data$agecat)
#table(data$agecat)

data$race[data$race=="not allowed to collect"]<-NA
data$race[data$race=="not reported"]<-NA
data$race[data$race=="other"]<-NA
data$race[data$race=="Unknown"]<-NA
data$race[data$race=="american indian or alaska native"]<-NA
data$race[data$race=="native hawaiian or other pacific islander"]<-NA
data$race<-droplevels(data$race)

data$primary_diagnosis[data$primary_diagnosis != "Acute myeloid leukemia, NOS" & data$primary_diagnosis != "Precursor B-cell lymphoblastic leukemia" & data$primary_diagnosis != "Multiple myeloma"]<-"Other"


data$tissue_or_organ_of_origin[data$tissue_or_organ_of_origin != "Bone marrow" & data$tissue_or_organ_of_origin != "Hematopoietic system, NOS"]<- "Other"
data$tissue_or_organ_of_origin<-droplevels(data$tissue_or_organ_of_origin)

data$site_of_resection_or_biopsy[which(data$site_of_resection_or_biopsy != "Bone marrow")]= "Other"
data$site_of_resection_or_biopsy<-as.factor(data$site_of_resection_or_biopsy)
```
Initially, Kaplan-Meier plots were fit on the data for visualization purposes, the first plot other than the average survival rate for everyone drops to about 77% after 1000 days, but the dropoff levels off afterwards. For better visualization, KM plots were generated for gender and for primary disease diagnosis. From here, we can see that females have a higher survival rate than males; and that Precursor B-cell lymphoblastic leukemia was disease with the highest survival rate, whole Acute myeloid leukemia had the lowest survival rate for the entire time period.



```{r,fig.width=3,fig.height=3,echo=FALSE}
#generating KM plots
msurv<-survfit(Surv(days_to_last_follow_up,vital_status)~1, data = data)

autoplot(msurv)
##############
msurv2<-survfit(Surv(days_to_last_follow_up,vital_status)~gender, data = data)

autoplot(msurv2)
##############
msurv3<-survfit(Surv(days_to_last_follow_up,vital_status)~ ethnicity, data = data)

#autoplot(msurv3)
##############
```

```{r,fig.width=8,fig.height=5,echo=FALSE}
msurv4<-survfit(Surv(days_to_last_follow_up,vital_status)~ primary_diagnosis, data = data)

autoplot(msurv4)
##############

msurv5<-survfit(Surv(days_to_last_follow_up,vital_status)~ site_of_resection_or_biopsy, data = data)

#autoplot(msurv5)
##############
msurv6<-survfit(Surv(days_to_last_follow_up,vital_status)~ agecat, data = data)

#autoplot(msurv6)
##############
msurv7<-survfit(Surv(days_to_last_follow_up,vital_status)~ race, data = data)

#autoplot(msurv7)

```
Some of the more complete variables that had a relation to Vital Status were: age, gender, ethnicity, race, tissue or organ of origin, site of resection or biopsy, and primary disease diagnosis. Using these variables, A Cox proportional Hazards model was constructed to see the effect these variables had on Vital Status, as well as to check if said effects were significant. A forest plot was used to depict these results. From this forest plot, we can see that the most significant factors were: if the individual was a male (p-value <.001), if they were in the 41-60 age range (p-value <.001), if they were black/African-American (p-value =.014), if the site of resection or autopsy was anywhere other than bone marrow (p-value <.001), or if their primary disease diagnosis was Precursor B-cell lymphoblastic leukemia (p-value <.001). 

```{r,echo = FALSE}

##this is the cox model for further analysis. not included because we were running low on space, 
cox<-coxph(formula=Surv(days_to_last_follow_up,vital_status)~ethnicity+gender+agecat+race+tissue_or_organ_of_origin+site_of_resection_or_biopsy+primary_diagnosis,data=data);#cox

ggforest(cox, data = data)

```



```{r, echo=FALSE}

```

## Machine Learning Modeling and Analysis

We also performed some machine learning modeling and evaluated the effectiveness of the models' prediction power of the vital status of certain patients.

### Models

#### Random Forest

After the missing values were imputed, we first tried to apply the random forest algorithm to that dataset. In order to fit the dataset into the model, we needed to remove categorical variables that had only one level since they were not suitable for random forest models. Then we ran the random forest algorithm using the training set that contains 70 percent of the original data, and we got the following plot.

```{r, echo=FALSE}
# Random Forest:

data_subset_rf <- complete(data_imp)
#summary(data_subset_rf)
# Remove variables that still have missing values
data_subset_rf <- subset(data_subset_rf, select = -c(morphology, primary_diagnosis))

# Apply random forest to the data
set.seed(625)
sample <- sample.split(data_subset_rf$vital_status, SplitRatio = .7)
train_rf <- subset(data_subset_rf, sample == TRUE)
test_rf  <- subset(data_subset_rf, sample == FALSE)
train_rf$vital_status <- factor(train_rf$vital_status)
test_rf$vital_status <- factor(test_rf$vital_status)
rf <- randomForest(vital_status ~ ., data=train_rf, na.action = na.omit)
```


```{r, echo=FALSE}
# Plot to see the performance of different number of trees
plot(rf, main = "Random Forest", xlim = range(0, 150))
```

The black line in the plot showed the out-of-bag (OOB) error that measuring the prediction error of random forests. We could see that when the number of trees is about 20, the prediction error was kind of low and the error kept nearly unchanged when the number of trees increased. So, we decided to choose 20 as the number of trees for our random forest algorithm. The following table showed the overall accuracy of the prediction using the random forest model.

```{r, echo=FALSE}
rf2 <- randomForest(vital_status ~ ., data=train_rf, na.action = na.omit, ntree = 20)

# Plot to see the importance of different variables on vital status
# varImpPlot(rf2, main = "Importance of the Variables")
```


```{r, echo=FALSE}
# Results:
# p1 <- predict(rf2, train_rf)
# p2 <- predict(rf2, test_rf)

# Training set confusion matrix info
train_rf_cm <- confusionMatrix(predict(rf2, train_rf), train_rf$vital_status)

# Testing set confusion matrix info
test_rf_cm <- confusionMatrix(predict(rf2, test_rf), test_rf$vital_status)
```

#### Neural Network

```{r, echo=FALSE}
# Neural Network:

data_subset_nn <- complete(data_imp)
# Remove variables that still have missing values
data_subset_nn <- subset(data_subset_nn, select = -c(morphology, primary_diagnosis))
```


```{r, echo=FALSE}
# Getting subset of factored variables in 'data_subset_nn'
data_subset_nn_factored_vars <- subset(data_subset_nn,
                                       select = c(project_id,
                                                  ethnicity,
                                                  gender,
                                                  race,
                                                  vital_status,
                                                  iss_stage,
                                                  site_of_resection_or_biopsy,
                                                  tissue_or_organ_of_origin))
data_subset_nn_factored_vars_mat <- as.matrix(data_subset_nn_factored_vars)

# Getting subset of non-factored variables in 'data_subset_nn'
data_subset_nn_nonfactored_vars <- subset(data_subset_nn,
                                          select = -c(project_id,
                                                      ethnicity,
                                                      gender,
                                                      race,
                                                      vital_status,
                                                      iss_stage,
                                                      site_of_resection_or_biopsy,
                                                      tissue_or_organ_of_origin))
data_subset_nn_nonfactored_vars_mat <- as.matrix(data_subset_nn_nonfactored_vars)

```


```{r, echo=FALSE}
# Getting dummy variables of each categorical feature
dummies <- fastDummies::dummy_cols(data_subset_nn_factored_vars)
dummies <- subset(dummies, select = -c(1:length(names(data_subset_nn_factored_vars))))
```


```{r, echo=FALSE}
# Normalization function for numerical variables, with missing values being ignored
normalize <- function(x){
  r <- rank(x) / sum(!is.na(x))
  r[is.na(x)] <- NA
  return(r)
}

# Getting normalized numerical variables, ignoring missing values
nn_nonfactored_vars_mat_normalized <- as.data.frame(
  apply(
    data_subset_nn_nonfactored_vars_mat, 2, normalize
  )
)
```


```{r, echo=FALSE}
# Combineing normalized numerical variables and categorical dummy variables
data_subset_nn_normalized <- cbind(nn_nonfactored_vars_mat_normalized, dummies)
data_subset_nn_normalized <- subset(data_subset_nn_normalized,
                                    select = -c(`vital_status_Dead`))
```


```{r, echo=FALSE}
# Renaming variable names for use in training the neural network model, by using underscores instead of spaces and hyphens
names(data_subset_nn_normalized) <- c(
  "age_at_index",
  "days_to_birth",
  "age_at_diagnosis",
  "days_to_last_follow_up",
  "days_to_last_known_disease_status",
  "project_id_BEATAML1.0_COHORT",
  "project_id_BEATAML1.0_CRENOLANIB",
  "project_id_CGCI_BLGSP",
  "project_id_GENIE_DFCI",
  "project_id_GENIE_JHU",
  "project_id_GENIE_MDA",
  "project_id_GENIE_MSK",
  "project_id_GENIE_UHN",
  "project_id_GENIE_VICC",
  "project_id_MMRF_COMMPASS",
  "project_id_OHSU_CNL",
  "project_id_TARGET_ALL_P1",
  "project_id_TARGET_ALL_P2",
  "project_id_TARGET_ALL_P3",
  "project_id_TARGET_AML",
  "project_id_TARGET_NBL",
  "project_id_TCGA_LAML",
  "ethnicity_hispanic",
  "ethnicity_not_hispanic",
  "gender_female",
  "gender_male",
  "race_ameri_ind_or_alaska",
  "race_asian",
  "race_black_or_afr_ameri",
  "race_hawaiian_or_pacific_islander",
  "race_other",
  "race_white",
  "vital_status_Alive",
  "iss_stage_I",
  "iss_stage_II",
  "iss_stage_III",
  "site_of_resection_or_biopsy_Abdomen_NOS",
  "site_of_resection_or_biopsy_Blood",
  "site_of_resection_or_biopsy_Bone_marrow",
  "site_of_resection_or_biopsy_Bones_of_skull_and_face",
  "site_of_resection_or_biopsy_Cheek_mucosa",
  "site_of_resection_or_biopsy_Connective_and_other_soft_tissues",
  "site_of_resection_or_biopsy_Connective_and_other_soft_tissues_NOS",
  "site_of_resection_or_biopsy_Intra_abdominal_lymph_nodes",
  "site_of_resection_or_biopsy_Kidney_NOS",
  "site_of_resection_or_biopsy_Lip_NOS",
  "site_of_resection_or_biopsy_Liver",
  "site_of_resection_or_biopsy_Lower_gum",
  "site_of_resection_or_biopsy_Lymph_nodes_of_head_face_neck",
  "site_of_resection_or_biopsy_Mandible",
  "site_of_resection_or_biopsy_Mouth_NOS",
  "site_of_resection_or_biopsy_Ovary",
  "site_of_resection_or_biopsy_Pelvis_NOS",
  "site_of_resection_or_biopsy_Peritoneum_NOS",
  "site_of_resection_or_biopsy_Retroperitoneum",
  "site_of_resection_or_biopsy_Small_intestine_NOS",
  "site_of_resection_or_biopsy_Specified_parts_of_peritoneum",
  "site_of_resection_or_biopsy_Spleen",
  "site_of_resection_or_biopsy_Testis_NOS",
  "site_of_resection_or_biopsy_Vestibule_of_mouth",
  "site_of_resection_or_biopsy_NA",
  "tissue_or_organ_of_origin_Bone_marrow",
  "tissue_or_organ_of_origin_Bones_of_skull_and_face",
  "tissue_or_organ_of_origin_Hematopoietic_system_NOS",
  "tissue_or_organ_of_origin_Orbit_NOS"
)
```


```{r, echo=FALSE}
# Removing missing values
data_subset_nn_normalized <- data_subset_nn_normalized[complete.cases(data_subset_nn_normalized), ]
```


After making dummy variables for every categorical feature and normalizing each numerical feature, several instances with missing values were removed, therefore the total number of instances in the overall neural network dataset was 6,916, before it was split into training and testing subsets. Prior to the removal of instances with missing values for the numerical features, there were a total of 12,587 instances in the dataset.


```{r, echo=FALSE}
# Splitting the normalized neural network dataset into training and testing subsets
set.seed(625)
train_ind <- sample(seq_len(nrow(data_subset_nn_normalized)),
                    size = floor(0.7 * nrow(data_subset_nn_normalized)))

train_nn <- data_subset_nn_normalized[train_ind,]
test_nn <- data_subset_nn_normalized[-train_ind,]
```


```{r, echo=FALSE}
## Neural Network
## (https://datascienceplus.com/neuralnet-train-and-test-neural-networks-using-r/)
## (http://uc-r.github.io/ann_classification)

# Making the neural network model
# start <- Sys.time()     #<== for timing the neural network model generation
nn <- neuralnet(vital_status_Alive ~ age_at_index + days_to_birth + age_at_diagnosis + days_to_last_follow_up + days_to_last_known_disease_status + project_id_BEATAML1.0_COHORT + project_id_BEATAML1.0_CRENOLANIB + project_id_CGCI_BLGSP + project_id_GENIE_DFCI + project_id_GENIE_JHU + project_id_GENIE_MDA + project_id_GENIE_MSK + project_id_GENIE_UHN + project_id_GENIE_VICC + project_id_MMRF_COMMPASS +  project_id_OHSU_CNL + project_id_TARGET_ALL_P1 + project_id_TARGET_ALL_P2 + project_id_TARGET_ALL_P3 + project_id_TARGET_AML + project_id_TARGET_NBL + project_id_TCGA_LAML + ethnicity_hispanic + ethnicity_not_hispanic + gender_female + gender_male + race_ameri_ind_or_alaska + race_asian +  race_black_or_afr_ameri + race_hawaiian_or_pacific_islander + race_other + race_white + iss_stage_I + iss_stage_II + iss_stage_III + site_of_resection_or_biopsy_Abdomen_NOS + site_of_resection_or_biopsy_Blood + site_of_resection_or_biopsy_Bone_marrow + site_of_resection_or_biopsy_Bones_of_skull_and_face + site_of_resection_or_biopsy_Cheek_mucosa + site_of_resection_or_biopsy_Connective_and_other_soft_tissues + site_of_resection_or_biopsy_Connective_and_other_soft_tissues_NOS + site_of_resection_or_biopsy_Intra_abdominal_lymph_nodes + site_of_resection_or_biopsy_Kidney_NOS + site_of_resection_or_biopsy_Lip_NOS + site_of_resection_or_biopsy_Liver + site_of_resection_or_biopsy_Lower_gum + site_of_resection_or_biopsy_Lymph_nodes_of_head_face_neck + site_of_resection_or_biopsy_Mandible + site_of_resection_or_biopsy_Mouth_NOS + site_of_resection_or_biopsy_Ovary + site_of_resection_or_biopsy_Pelvis_NOS + site_of_resection_or_biopsy_Peritoneum_NOS + site_of_resection_or_biopsy_Retroperitoneum + site_of_resection_or_biopsy_Small_intestine_NOS + site_of_resection_or_biopsy_Specified_parts_of_peritoneum + site_of_resection_or_biopsy_Spleen + site_of_resection_or_biopsy_Testis_NOS + site_of_resection_or_biopsy_Vestibule_of_mouth + site_of_resection_or_biopsy_NA + tissue_or_organ_of_origin_Bone_marrow + tissue_or_organ_of_origin_Bones_of_skull_and_face + tissue_or_organ_of_origin_Hematopoietic_system_NOS + tissue_or_organ_of_origin_Orbit_NOS,
                data=train_nn,
                hidden=c(50, 10),#c(50, 10),
                linear.output=FALSE,
                threshold=0.01)
# end <- Sys.time()       #<== for timing the neural network model generation
# end - start             #<== for timing the neural network model generation
```


```{r, echo=FALSE}
# Plot to view neural network model, though it is pretty complicated given the number of nodes involved in the input layer and the hidden layers

# plot(nn)
```

```{r, echo=FALSE}
# Evaluating the model's accuracy
prediction_threshold <- 0.5
train_prediction <- predict(nn, train_nn)
test_prediction <- predict(nn, test_nn)

train_prediction[train_prediction >= prediction_threshold] <- 1
train_prediction[train_prediction < prediction_threshold] <- 0
# train_prediction <- c(train_prediction)
train_actual <- train_nn$vital_status_Alive

test_prediction[test_prediction >= prediction_threshold] <- 1
test_prediction[test_prediction < prediction_threshold] <- 0
# test_prediction <- c(test_prediction)
test_actual <- test_nn$vital_status_Alive

# Training set confusion matrix info
train_nn_cm <- confusionMatrix(factor(train_prediction), factor(train_actual))

# Testing set confusion matrix info
test_nn_cm <- confusionMatrix(factor(test_prediction), factor(test_actual))
```

### Model Results

```{r, echo=FALSE}
# Model accuracies across training and testing sets
print("Model accuracies across training and testing sets:")
model_accuracies <- data.frame(
  "Model" = c(rep("Random Forest", 2), rep("Neural Network", 2)),
  "Training/Testing Set" = c(rep(c("Training", "Testing"), 2)),
  "Accuracy" = c(train_rf_cm$overall[1], test_rf_cm$overall[1], train_nn_cm$overall[1], test_nn_cm$overall[1])
)
kable(model_accuracies)
```

```{r, echo=FALSE}
# Model testing set confusion matrices
print("Random forest testing set confusion matrix:")
test_rf_cm$table
cat("", sep="\n\n")

# Neural Network
print("Neural network testing set confusion matrix:")
test_nn_cm$table
```

# Results and Conclusion

For the random forest algorithm with 20 trees, the accuracy of prediction for both the training set and the testing set were more than 99.5%. The accuracy would still be above 99% if we changed the number of trees to 10. The performance of the prediction looked great, but such a high accuracy in both the training set and testing set may indicate some potential inflexibility when applying the same model to a totally new dataset. For the neural network model, with 2 hidden layers consisting of 50 nodes first and then 10 nodes, the accuracy of prediction for both the training set and the testing set were more than 97%. The results of this model is quite promising, as the neural network was able to make many accurate predictions, but they were slightly less than the results of the random forest model. Same as what mentioned in the previous model, such a high accuracy in both the training set and testing set may indicate problems when the same algorithm is applied to a completely different dataset. Hence, it may be ideal to re-train both models when we work on a brand new bone marrow cancer data set.

Additionally, it takes under 50 minutes to generate the neural network model, trained using the training subset. It could probably be sped up using cloud computing services such as Great Lakes, AWS, etc.

# Division of Work:

Yitian: worked on initial data preprocessing by transforming all variables into numeric values or factors, then worked on data imputation and data cleaning, and finally implemented and evaluated the random forest model.

Rudra: worked on initial data preprocessing by converting empty values to `NA`, then did further preprocessing of the data for the neural network model, and finally implemented and evaluated the neural network model.

Jorge:
