---
title: "Survival Analysis and Machine Learning Methodologies for Bone Marrow Cancer"
output:
  pdf_document:
    fig_width: 5.5
    fig_height: 3.5
  html_document:
    toc: yes
    theme: united
header-includes: \usepackage{setspace}\doublespacing
author: Yitian Cai, Rudra Guin, Jorge Portugal
date: "12/17/2021"
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```


# Introduction

For this project, our group chose to perform statistical analysis using the Clinical Data Set from the Clinical Package of bone marrow cancer data. It was collected from the National Cancer Institute (NCI) genomic data portal. The version of the dataset we used was released by October 29, 2021. The bone marrow cancer can damage the bones, immune system, kidneys, and red blood cell count. The dataset contains 16,029 different cases of bone marrow cancer. We planned on using it for survival analysis and machine learning methodologies.

# Data Description
The dataset contains 47 clinical variables. At the beginning, we tried to include the biospecimen data in order to increase the dimension of our dataset, but we found that most of those genomics data were missing, which would not provide us too much help. So, we decided to stick with the clinical data of bone marrow. Vital status means whether the patients were alive or dead at the time the data were collected. Our dataset contains 9,036 alive cases and 3,551 dead cases. Others were either missing or recorded as "unknown" or "not reported".

# Data Preprocessing

The initial dataset has several missing values among the different features. So, before going into analysis and modeling, we first clean up and pre-process the data. First, we remove all the observations that have missing values for vital status, because vital status is the one we wish to forecast or predict. Then, we decided to remove variables with more than 8,000 missing values. Because it means that more than half of the observations in these variables were missing, which we believe will cause too much inaccuracy after data imputation. After that, we used mice() to impute those missing values. The mice package implements a method to deal with missing data and it generates Multivariate Imputations by Chained Equations. And finally, we randomly split the dataset into two where the training set contains 70% of the data, and the test set contains the rest 30% of the data.

```{r, echo=FALSE, message=FALSE}
# Necessary libraries
library(mice)
library(fastDummies)
library(neuralnet)
library(caret)
library(randomForest)
library(caTools)
set.seed(625)
```


```{r, echo=FALSE}
# Loading the clinical data
data <- read.delim(file = 'clinical_bone.tsv', sep = '\t', header = TRUE)
data[data == "\'--"] <- "NULL"
is.na(data) <- data == "NULL"
data <- data[, colSums(is.na(data)) < nrow(data)]
#names(data)

# Transforming unknown values into NAs
data[data=="not reported"] <- NA
data[data=="Not Reported"] <- NA
data[data=="unknown"] <- NA
data[data=="Unknown"] <- NA
data[data=="not allowed to collect"] <- NA
#summary(data)
```

```{r, echo=FALSE}
# Tranforming the type of variables into numerical or categorical
data <- subset(data, select = -c(case_id, case_submitter_id))
data <- transform(
  data,
  project_id=as.factor(project_id),
  age_at_index=as.numeric(age_at_index),
  age_is_obfuscated=as.factor(age_is_obfuscated),
  cause_of_death=as.factor(cause_of_death),
  days_to_birth=as.numeric(days_to_birth),
  days_to_death=as.numeric(days_to_death),
  ethnicity=as.factor(ethnicity),
  gender=as.factor(gender),
  race=as.factor(race),
  vital_status=as.factor(vital_status),
  year_of_birth=as.numeric(year_of_birth),
  year_of_death=as.numeric(year_of_death),
  age_at_diagnosis=as.numeric(age_at_diagnosis),
  ann_arbor_b_symptoms=as.factor(ann_arbor_b_symptoms),
  ann_arbor_extranodal_involvement=as.factor(ann_arbor_extranodal_involvement),
  ann_arbor_pathologic_stage=as.factor(ann_arbor_pathologic_stage),
  burkitt_lymphoma_clinical_variant=as.factor(burkitt_lymphoma_clinical_variant),
  classification_of_tumor=as.factor(classification_of_tumor),
  days_to_diagnosis=as.numeric(days_to_diagnosis),
  days_to_last_follow_up=as.numeric(days_to_last_follow_up),
  days_to_last_known_disease_status=as.numeric(days_to_last_known_disease_status),
  inss_stage=as.numeric(inss_stage),
  iss_stage=as.factor(iss_stage),
  last_known_disease_status=as.factor(last_known_disease_status),
  method_of_diagnosis=as.factor(method_of_diagnosis),
  morphology=as.factor(morphology),
  primary_diagnosis=as.factor(primary_diagnosis),
  prior_malignancy=as.factor(prior_malignancy),
  prior_treatment=as.factor(prior_treatment),
  progression_or_recurrence=as.factor(progression_or_recurrence),
  site_of_resection_or_biopsy=as.factor(site_of_resection_or_biopsy),
  synchronous_malignancy=as.factor(synchronous_malignancy),
  tissue_or_organ_of_origin=as.factor(tissue_or_organ_of_origin),
  tumor_grade=as.factor(tumor_grade),
  year_of_diagnosis=as.numeric(year_of_diagnosis),
  days_to_treatment_end=as.numeric(days_to_treatment_end),
  days_to_treatment_start=as.numeric(days_to_treatment_start),
  initial_disease_status=as.factor(initial_disease_status),
  number_of_cycles = as.factor(number_of_cycles),
  regimen_or_line_of_therapy = as.factor(regimen_or_line_of_therapy),
  therapeutic_agents=as.factor(therapeutic_agents),
  treatment_anatomic_site=as.factor(treatment_anatomic_site),
  treatment_dose=as.factor(treatment_dose),
  treatment_intent_type=as.factor(treatment_intent_type),
  treatment_or_therapy=as.factor(treatment_or_therapy),
  treatment_outcome=as.factor(treatment_outcome),
  treatment_type=as.factor(treatment_type)
)
```



```{r, echo=FALSE}
# Remove variables with missing values in vital status
data2 <- data[!is.na(data$vital_status), ]

# Remove variables with more than 8,000 missing values
rem <- colSums(is.na(data)) > 8000
data2 <- subset(data2, select = -c(age_is_obfuscated, cause_of_death, days_to_death, year_of_birth, year_of_death, ann_arbor_b_symptoms, ann_arbor_extranodal_involvement, ann_arbor_pathologic_stage, burkitt_lymphoma_clinical_variant, classification_of_tumor, days_to_diagnosis, inss_stage, last_known_disease_status, method_of_diagnosis, prior_malignancy, prior_treatment, progression_or_recurrence, synchronous_malignancy, tumor_grade, year_of_diagnosis, days_to_treatment_end, days_to_treatment_start, initial_disease_status, number_of_cycles, regimen_or_line_of_therapy, therapeutic_agents, treatment_anatomic_site, treatment_dose, treatment_intent_type, treatment_or_therapy, treatment_outcome, treatment_type))

# summary(data)
```

```{r, echo=FALSE}
# Impute missing values
data_imp <- mice(data2, m=5, method = "sample", printFlag = FALSE)
```


# Analysis

## Survival Analysis

We first conducted some survival analysis 

```{r}

```

## Machine Learning Modeling and Analysis

We also performed some machine learning modeling and evaluated the effectiveness of the models' prediction power of the vital status of certain patients.

### Random Forest

```{r, echo=FALSE}
# Random Forest:

data_subset_rf <- complete(data_imp)
#summary(data_subset_rf)
# Remove variables that still have missing values
data_subset_rf <- subset(data_subset_rf, select = -c(morphology, primary_diagnosis))

# Apply random forest to the data
sample <- sample.split(data_subset_rf$vital_status, SplitRatio = .7)
train_rf <- subset(data_subset_rf, sample == TRUE)
test_rf  <- subset(data_subset_rf, sample == FALSE)
train_rf$vital_status <- factor(train_rf$vital_status)
test_rf$vital_status <- factor(test_rf$vital_status)
rf <- randomForest(vital_status ~ ., data=train_rf, na.action = na.omit)
```


```{r, echo=FALSE}
# Plot to see the performance of different number of trees
plot(rf, main = "Random Forest", xlim = range(0, 150))
```

```{r, echo=FALSE}
rf2 <- randomForest(vital_status ~ ., data=train_rf, na.action = na.omit, ntree = 20)

# Plot to see the importance of different variables on vital status
varImpPlot(rf2, main = "Importance of the Variables")
```


```{r, echo=FALSE}
# Results:
# p1 <- predict(rf2, train_rf)
# p2 <- predict(rf2, test_rf)

# Training set confusion matrix
print("Training set confusion matrix and accuracies:")
train_cm <- confusionMatrix(predict(rf2, train_rf), train_rf$vital_status)
train_cm$table
train_cm$overall
cat("", sep="\n\n")

# Testing set confusion matrix
print("Testing set confusion matrix and accuracies:")
test_cm <- confusionMatrix(predict(rf2, test_rf), test_rf$vital_status)
test_cm$table
test_cm$overall
```

### Neural Network

```{r, echo=FALSE}
# Neural Network:

data_subset_nn <- complete(data_imp)
data_subset_nn <- subset(data_subset_nn, select = -c(morphology, primary_diagnosis))
```


```{r, echo=FALSE}
# Getting subset of factored variables in 'data_subset_nn'
data_subset_nn_factored_vars <- subset(data_subset_nn,
                                       select = c(project_id,
                                                  ethnicity,
                                                  gender,
                                                  race,
                                                  vital_status,
                                                  iss_stage,
                                                  site_of_resection_or_biopsy,
                                                  tissue_or_organ_of_origin))
data_subset_nn_factored_vars_mat <- as.matrix(data_subset_nn_factored_vars)

# Getting subset of non-factored variables in 'data_subset_nn'
data_subset_nn_nonfactored_vars <- subset(data_subset_nn,
                                          select = -c(project_id,
                                                      ethnicity,
                                                      gender,
                                                      race,
                                                      vital_status,
                                                      iss_stage,
                                                      site_of_resection_or_biopsy,
                                                      tissue_or_organ_of_origin))
data_subset_nn_nonfactored_vars_mat <- as.matrix(data_subset_nn_nonfactored_vars)

```


```{r, echo=FALSE}
# Getting dummy variables of each categorical feature
dummies <- fastDummies::dummy_cols(data_subset_nn_factored_vars)
dummies <- subset(dummies, select = -c(1:length(names(data_subset_nn_factored_vars))))
```


```{r, echo=FALSE}
# Normalization function for numerical variables, with missing values being ignored
normalize <- function(x){
  r <- rank(x) / sum(!is.na(x))
  r[is.na(x)] <- NA
  return(r)
}

# Getting normalized numerical variables, ignoring missing values
nn_nonfactored_vars_mat_normalized <- as.data.frame(
  apply(
    data_subset_nn_nonfactored_vars_mat, 2, normalize
  )
)
```


```{r, echo=FALSE}
# Combineing normalized numerical variables and categorical dummy variables
data_subset_nn_normalized <- cbind(nn_nonfactored_vars_mat_normalized, dummies)
data_subset_nn_normalized <- subset(data_subset_nn_normalized,
                                    select = -c(`vital_status_Dead`))
```


```{r, echo=FALSE}
# Renaming variable names for use in training the neural network model, by using underscores instead of spaces and hyphens
names(data_subset_nn_normalized) <- c(
  "age_at_index",
  "days_to_birth",
  "age_at_diagnosis",
  "days_to_last_follow_up",
  "days_to_last_known_disease_status",
  "project_id_BEATAML1.0_COHORT",
  "project_id_BEATAML1.0_CRENOLANIB",
  "project_id_CGCI_BLGSP",
  "project_id_GENIE_DFCI",
  "project_id_GENIE_JHU",
  "project_id_GENIE_MDA",
  "project_id_GENIE_MSK",
  "project_id_GENIE_UHN",
  "project_id_GENIE_VICC",
  "project_id_MMRF_COMMPASS",
  "project_id_OHSU_CNL",
  "project_id_TARGET_ALL_P1",
  "project_id_TARGET_ALL_P2",
  "project_id_TARGET_ALL_P3",
  "project_id_TARGET_AML",
  "project_id_TARGET_NBL",
  "project_id_TCGA_LAML",
  "ethnicity_hispanic",
  "ethnicity_not_hispanic",
  "gender_female",
  "gender_male",
  "race_ameri_ind_or_alaska",
  "race_asian",
  "race_black_or_afr_ameri",
  "race_hawaiian_or_pacific_islander",
  "race_other",
  "race_white",
  "vital_status_Alive",
  "iss_stage_I",
  "iss_stage_II",
  "iss_stage_III",
  "site_of_resection_or_biopsy_Abdomen_NOS",
  "site_of_resection_or_biopsy_Blood",
  "site_of_resection_or_biopsy_Bone_marrow",
  "site_of_resection_or_biopsy_Bones_of_skull_and_face",
  "site_of_resection_or_biopsy_Cheek_mucosa",
  "site_of_resection_or_biopsy_Connective_and_other_soft_tissues",
  "site_of_resection_or_biopsy_Connective_and_other_soft_tissues_NOS",
  "site_of_resection_or_biopsy_Head_face_or_neck_NOS",
  "site_of_resection_or_biopsy_Hematopoietic_system_NOS",
  "site_of_resection_or_biopsy_Intra_abdominal_lymph_nodes",
  "site_of_resection_or_biopsy_Kidney_NOS",
  "site_of_resection_or_biopsy_Lip_NOS",
  "site_of_resection_or_biopsy_Liver",
  "site_of_resection_or_biopsy_Lower_gum",
  "site_of_resection_or_biopsy_Lymph_nodes_of_head_face_neck",
  "site_of_resection_or_biopsy_Mandible",
  "site_of_resection_or_biopsy_Mouth_NOS",
  "site_of_resection_or_biopsy_Ovary",
  "site_of_resection_or_biopsy_Pelvis_NOS",
  "site_of_resection_or_biopsy_Peritoneum_NOS",
  "site_of_resection_or_biopsy_Retroperitoneum",
  "site_of_resection_or_biopsy_Small_intestine_NOS",
  "site_of_resection_or_biopsy_Specified_parts_of_peritoneum",
  "site_of_resection_or_biopsy_Spleen",
  "site_of_resection_or_biopsy_Testis_NOS",
  "site_of_resection_or_biopsy_Vestibule_of_mouth",
  "tissue_or_organ_of_origin_Bone_marrow",
  "tissue_or_organ_of_origin_Bones_of_skull_and_face",
  "tissue_or_organ_of_origin_Hematopoietic_system_NOS",
  "tissue_or_organ_of_origin_Orbit_NOS"
)
```


```{r, echo=FALSE}
# Removing missing values
data_subset_nn_normalized <- data_subset_nn_normalized[complete.cases(data_subset_nn_normalized), ]
```


After making dummy variables for every categorical feature and normalizing each numerical feature, several instances with missing values were removed, therefore the total number of instances in the overall neural network dataset was 6916, before it was split into training and testing subsets. Prior to the removal of instances with missing values for the numerical features, there were a total of 12587 instances in the dataset.


```{r, echo=FALSE}
# Splitting the normalized neural network dataset into training and testing subsets
train_ind <- sample(seq_len(nrow(data_subset_nn_normalized)),
                    size = floor(0.7 * nrow(data_subset_nn_normalized)))

train_nn <- data_subset_nn_normalized[train_ind,]
test_nn <- data_subset_nn_normalized[-train_ind,]
```


It takes under 50 minutes to generate the neural network model, trained using the training subset. It could probably be sped up using services such as Great Lakes, etc.


```{r, echo=FALSE}
## Neural Network
## (https://datascienceplus.com/neuralnet-train-and-test-neural-networks-using-r/)
## (http://uc-r.github.io/ann_classification)

# Making the neural network model
# start <- Sys.time()     <== for timing the neural network model generation
nn <- neuralnet(vital_status_Alive ~ age_at_index + days_to_birth + age_at_diagnosis + days_to_last_follow_up + days_to_last_known_disease_status + project_id_BEATAML1.0_COHORT + project_id_BEATAML1.0_CRENOLANIB + project_id_CGCI_BLGSP + project_id_GENIE_DFCI + project_id_GENIE_JHU + project_id_GENIE_MDA + project_id_GENIE_MSK + project_id_GENIE_UHN + project_id_GENIE_VICC + project_id_MMRF_COMMPASS +  project_id_OHSU_CNL + project_id_TARGET_ALL_P1 + project_id_TARGET_ALL_P2 + project_id_TARGET_ALL_P3 + project_id_TARGET_AML + project_id_TARGET_NBL + project_id_TCGA_LAML + ethnicity_hispanic + ethnicity_not_hispanic + gender_female + gender_male + race_ameri_ind_or_alaska + race_asian +  race_black_or_afr_ameri + race_hawaiian_or_pacific_islander + race_other + race_white + iss_stage_I + iss_stage_II + iss_stage_III + site_of_resection_or_biopsy_Abdomen_NOS + site_of_resection_or_biopsy_Blood + site_of_resection_or_biopsy_Bone_marrow + site_of_resection_or_biopsy_Bones_of_skull_and_face + site_of_resection_or_biopsy_Cheek_mucosa + site_of_resection_or_biopsy_Connective_and_other_soft_tissues + site_of_resection_or_biopsy_Connective_and_other_soft_tissues_NOS + site_of_resection_or_biopsy_Head_face_or_neck_NOS + site_of_resection_or_biopsy_Hematopoietic_system_NOS + site_of_resection_or_biopsy_Intra_abdominal_lymph_nodes + site_of_resection_or_biopsy_Kidney_NOS + site_of_resection_or_biopsy_Lip_NOS + site_of_resection_or_biopsy_Liver + site_of_resection_or_biopsy_Lower_gum + site_of_resection_or_biopsy_Lymph_nodes_of_head_face_neck + site_of_resection_or_biopsy_Mandible + site_of_resection_or_biopsy_Mouth_NOS + site_of_resection_or_biopsy_Ovary + site_of_resection_or_biopsy_Pelvis_NOS + site_of_resection_or_biopsy_Peritoneum_NOS + site_of_resection_or_biopsy_Retroperitoneum + site_of_resection_or_biopsy_Small_intestine_NOS + site_of_resection_or_biopsy_Specified_parts_of_peritoneum + site_of_resection_or_biopsy_Spleen + site_of_resection_or_biopsy_Testis_NOS + site_of_resection_or_biopsy_Vestibule_of_mouth + tissue_or_organ_of_origin_Bone_marrow + tissue_or_organ_of_origin_Bones_of_skull_and_face + tissue_or_organ_of_origin_Hematopoietic_system_NOS + tissue_or_organ_of_origin_Orbit_NOS,
                data=train_nn,
                hidden=c(50, 10),#c(50, 10),
                linear.output=FALSE,
                threshold=0.01)
# end <- Sys.time()       <== for timing the neural network model generation
# end - start             <== for timing the neural network model generation
```


```{r, echo=FALSE}
# Plot to view neural network model, though it is pretty complicated given the number of nodes involved in the input layer and the hidden layers

# plot(nn)
```

```{r, echo=FALSE}
# Evaluating the model's accuracy
prediction_threshold <- 0.5
train_nn_results <- compute(nn, train_nn)
test_nn_results <- compute(nn, test_nn)

train_prediction <- train_nn_results$net.result
train_prediction[train_prediction >= prediction_threshold] <- 1
train_prediction[train_prediction < prediction_threshold] <- 0
train_prediction <- c(train_prediction)
train_actual <- train_nn$vital_status_Alive

test_prediction <- test_nn_results$net.result
test_prediction[test_prediction >= prediction_threshold] <- 1
test_prediction[test_prediction < prediction_threshold] <- 0
test_prediction <- c(test_prediction)
test_actual <- test_nn$vital_status_Alive

# Training set confusion matrix
print("Training set confusion matrix and accuracies:")
train_cm <- confusionMatrix(factor(train_prediction), factor(train_actual))
train_cm$table
train_cm$overall
cat("", sep="\n\n")

# Testing set confusion matrix
print("Testing set confusion matrix and accuracies:")
test_cm <- confusionMatrix(factor(test_prediction), factor(test_actual))
test_cm$table
test_cm$overall
```

# Results


# Conclusion


# Division of Work:

Yitian: worked on initial data preprocessing by transforming all variables into numeric or factor, then worked on data imputation and data cleaning, and finally implemented and evaluated the random forest model.

Rudra: worked on initial data preprocessing by converting empty values to `NA`, then did further preprocessing of the data for the neural network model, and finally implemented and evaluated the neural network model.

Jorge:
